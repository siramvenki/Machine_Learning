{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title : Author Labeling by text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is one of the major applications of Machine Learning. Most of the text classification projects are done by implementing any of the Machine Learning Algorithms. In this project we will use Naive_Bayes algorithm to label the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Preprocessing :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The student assignments of English class are used as input for this project and we have to label the text with respective author(student). The data we received has repetative content for every student, we have dropped such type of files from the input data and the student records with fewer files were also dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus evolved data is processed to generate the \".csv\" file which is used as input dataset for this project. It contains two columns, one with student roll number and other with corresponding text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rollNo</th>\n",
       "      <th>textData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ESSAY WRITINGQ1.Essay-1:1.Helping the people i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Q. Make the sentences more concise:1. We certa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Creative WritingA Photographer has got a chanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1)---------------------------------A. NareshIf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>To: Subject: Regarding Performance FeedbackHel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rollNo                                           textData\n",
       "1       1  ESSAY WRITINGQ1.Essay-1:1.Helping the people i...\n",
       "1      10  Q. Make the sentences more concise:1. We certa...\n",
       "1      11  Creative WritingA Photographer has got a chanc...\n",
       "1      13  1)---------------------------------A. NareshIf...\n",
       "1      14  To: Subject: Regarding Performance FeedbackHel..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas library\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loding the data set\n",
    "df = pd.read_table('data.csv',\n",
    "                   sep=',', \n",
    "                   header=None, \n",
    "                   names=['rollNo','textData'])\n",
    "\n",
    "# Output printing out first 5 columns\n",
    "\n",
    "df.head()\n",
    "# from sklearn.feature_extraction import text \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows the first 5 tuples of the dataset which contains two columns namely the roll no and text of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape is used to get the details of the data set.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 1028 entries (tuples) and 2 columns as described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the dataset into a training and testing set by using the train_test_split method in sklearn.\n",
    "Spliting the data by using the following variables:<br />\n",
    "-> X_train is our training data for the 'textData' column. <br />\n",
    "-> y_train is our training data for the 'rollNo' column<br />\n",
    "-> X_test is our testing data for the 'textData' column.<br />\n",
    "-> y_test is our testing data for the 'rollNo' column.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 1028\n",
      "Number of rows in the training set: 771\n",
      "Number of rows in the test set: 257\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing sets\n",
    "# USE from sklearn.model_selection import train_test_split to avoid seeing deprecation warning.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['textData'], \n",
    "                                                    df['rollNo'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Printing out the number of rows we have in each our training and testing data.\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bag of Words processing to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have split the data, next we will generate Bag of words and convert our data into the desired matrix format.\n",
    "We will be using CountVectorizer() which is in sklearn library.<br />\n",
    "-> First we have to fit our training data (X_train) into CountVectorizer() and return the matrix.<br />\n",
    "-> Later we have to transform our testing data (X_test) to return the matrix.<br />\n",
    "\n",
    "Here X_train is our training data for the 'textData' column in our dataset and we will be using this to train our model.<br/>\n",
    "\n",
    "X_test is our testing data for the 'textData' column and this is the data we will be using(after transformation to a matrix) to make predictions on. We will then compare those predictions with y_test later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer(stop_words=\"english\", token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning a vocabulary dictionary for the training data and then transforming the data into a document-term matrix and next for the testing data here we are only transforming the data into a document-term matrix. <br />\n",
    "\n",
    "We have passed arguments to customize the count_vector which involved removing stop words of english language and puntuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes implementation using scikit-learn :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use sklearns sklearn.naive_bayes method to make predictions on our dataset.\n",
    "\n",
    "Specifically, we will use the multinomial Naive Bayes implementation which is suitable for classification with discrete features (such as in our case, word counts for text classification). It takes in integer word counts as its input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training data into the variable 'training_data' and the testing data into the variable 'testing_data'.\n",
    "\n",
    "We will import the MultinomialNB classifier and fit the training data into the classifier using fit() and we will train the classifier using 'training_data' and 'y_train' which we have from our split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm has been trained using the training data set we can now make some predictions on the test data\n",
    "stored in 'testing_data' using predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the accuracy, precision, recall and F1 scores of our model using your test data 'y_test' and the predictions\n",
    "we made earlier stored in the 'predictions' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy score: ', '0.221789883268')\n",
      "('Precision score: ', '0.187706099766')\n",
      "('Recall score: ', '0.221789883268')\n",
      "('F1 score: ', '0.18274968629')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions,average=\"weighted\")))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average=\"weighted\")))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is very low for the model we developed, from this we can conclude that the dataset used for generating the model is very little and there is also a possibility of common data (Student assignment texts)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
